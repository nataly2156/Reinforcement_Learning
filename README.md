# Proyecto de Aprendizaje por Refuerzo - GridWorld Q-Learning

Aplicaci贸n web interactiva que implementa un agente inteligente mediante el algoritmo Q-Learning para resolver un problema de navegaci贸n en un entorno tipo GridWorld. El proyecto muestra de forma clara c贸mo un agente aprende una pol铆tica 贸ptima a trav茅s de la exploraci贸n y la interacci贸n continua con un entorno discreto.


## *Descripci贸n del Entorno*

El proyecto utiliza un entorno tipo GridWorld, una cuadr铆cula donde un agente debe desplazarse desde una posici贸n inicial hacia una meta evitando obst谩culos. Las caracter铆sticas principales del entorno son:

- Grid de tama帽o configurable (por defecto 5x5).
- Posici贸n inicial ubicada en la esquina superior izquierda.
- Meta ubicada en la esquina inferior derecha.
- Obst谩culos distribuidos en posiciones fijas dentro del grid.
- Acciones permitidas: moverse arriba, abajo, izquierda y derecha.
- Restricciones: el agente no puede salir del grid y no puede atravesar obst谩culos.
- Funci贸n de recompensa basada en penalizar pasos innecesarios, castigar choques y premiar alcanzar la meta.

Este entorno permite observar con claridad la evoluci贸n del aprendizaje del agente y la forma en que decide sus trayectorias.


## *Descripci贸n del Algoritmo Utilizado*

El agente implementa el algoritmo Q-Learning, un m茅todo de aprendizaje por refuerzo off-policy que aprende el valor 贸ptimo de cada par estado-acci贸n mediante interacci贸n repetida con el entorno.

Aspectos clave del algoritmo:

- Uso de una pol铆tica epsilon-greedy para equilibrar exploraci贸n y explotaci贸n.
- Actualizaci贸n de la tabla Q basada en la ecuaci贸n de Bellman.
- Aprendizaje libre de modelo: no requiere conocer din谩micas internas del entorno.
- Uso de hiperpar谩metros como la tasa de aprendizaje, factor de descuento, valor inicial de epsilon y su decaimiento.
- Entrenamiento mediante episodios completos que inician desde el estado inicial y finalizan al llegar a la meta o agotar los pasos permitidos.

El algoritmo ajusta gradualmente los valores Q hasta converger hacia una pol铆tica cada vez m谩s eficiente.


## *Descripci贸n del Comportamiento Obtenido*

Durante el entrenamiento se observ贸 la progresi贸n del agente en su capacidad de navegaci贸n:

- En los primeros episodios predomina la exploraci贸n y el agente realiza movimientos aleatorios, con frecuentes choques contra obst谩culos.
- A medida que el epsilon disminuye, el agente identifica trayectorias favorables y reduce el n煤mero de pasos necesarios para alcanzar la meta.
- En etapas avanzadas del entrenamiento la pol铆tica se estabiliza, logrando comportamientos consistentes y cercanos a la ruta 贸ptima.
- Las recompensas acumuladas aumentan progresivamente y el n煤mero de pasos decrece, evidenciando la mejora en la calidad de las decisiones.
- Finalmente, el agente aprende una ruta eficiente evitando obst谩culos y alcanzando la meta de forma estable.

Este comportamiento demuestra la efectividad del algoritmo Q-Learning para adquirir estrategias de navegaci贸n 贸ptimas en entornos discretos como GridWorld.


*隆Gracias por explorar nuestro proyecto de Aprendizaje por Refuerzo! *
